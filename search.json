[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pip Technical Guidelines",
    "section": "",
    "text": "Preface\nWelcome to the PIP Technical Guidelines, a living technical resource for the Poverty and Inequality Platform (PIP) team at the World Bank.\nThis book serves as a centralized knowledge base for the technical infrastructure, development workflows, and best practices that support our data science and statistical work. As the PIP ecosystem continues to evolve—spanning R packages, Stata analysis, version control, automation, and AI-assisted coding—this guide provides practical, field-tested solutions to common technical challenges our team encounters.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#purpose",
    "href": "index.html#purpose",
    "title": "Pip Technical Guidelines",
    "section": "Purpose",
    "text": "Purpose\nThe primary objectives of this book are to:\n\nDocument technical workflows specific to PIP projects, including environment setup, development tools, and deployment processes\nStandardize best practices across R, Stata, GitHub, VS Code, and other tools used in our daily work\nAccelerate onboarding by providing new team members with clear, step-by-step instructions for configuring their development environment\nPromote consistency in how we write, test, document, and maintain code across different projects and programming languages\nPreserve institutional knowledge that would otherwise exist only in individual team members’ setups or undocumented workflows",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#scope",
    "href": "index.html#scope",
    "title": "Pip Technical Guidelines",
    "section": "Scope",
    "text": "Scope\nThis book focuses on technical infrastructure and development practices, not statistical methodologies or economic theory. You’ll find guidance on:\n\nSetting up R, RStudio, and Positron with unified configurations\nConfiguring VS Code for Stata development with automated workflows\nIntegrating Git and GitHub into daily work with proper authentication and branching strategies\nImplementing GitHub Actions for continuous integration and automated deployment\nUsing GitHub Copilot responsibly and effectively, with mandatory protocols for code quality\nOptimizing performance on World Bank laptops and virtual machines\nManaging code coverage, testing frameworks, and documentation standards",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "Pip Technical Guidelines",
    "section": "Audience",
    "text": "Audience\nThis guide is written for PIP team members; data scientists, economists, and developers working with R, Stata, and related tools. While many sections assume familiarity with programming concepts, we provide step-by-step instructions designed to work in the World Bank’s computing environment.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#a-living-document",
    "href": "index.html#a-living-document",
    "title": "Pip Technical Guidelines",
    "section": "A Living Document",
    "text": "A Living Document\nThis book is continuously evolving. As we adopt new tools, refine existing workflows, or solve novel technical challenges, we add new chapters and update existing content. Each chapter represents accumulated team knowledge, battle-tested in real projects, and refined through practical experience.\nWe welcome contributions, corrections, and suggestions from all team members as we build this resource together.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "setupR.html",
    "href": "setupR.html",
    "title": "1  Setting Up R, RStudio, and Positron to Use the Same Configuration Files",
    "section": "",
    "text": "1.1 Intro\nWhen working with R, your environment files (.Renviron and .Rprofile) control how R behaves on startup—what packages it loads, what paths it uses, and how it connects to external resources (like CRAN mirrors or proxies).\nHowever, depending on which IDE you use (RStudio, Positron, VS Code, or command-line R), these files might not always point to the same location.\nA clean, unified setup ensures: - Reproducible environments across IDEs.\n- Consistent library paths (.libPaths() output).\n- Fewer surprises when running automated scripts, R Markdown documents, or package builds.\n- Fewer “it works on my RStudio but not on Positron” headaches.\nThis guide describes the recommended setup for aligning your R environment across IDEs, including RStudio and Positron.",
    "crumbs": [
      "R Setup and efficiency",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R, RStudio, and Positron to Use the Same Configuration Files</span>"
    ]
  },
  {
    "objectID": "setupR.html#step-1.-choose-a-canonical-r-configuration-directory",
    "href": "setupR.html#step-1.-choose-a-canonical-r-configuration-directory",
    "title": "1  Setting Up R, RStudio, and Positron to Use the Same Configuration Files",
    "section": "1.2 Step 1. Choose a canonical R configuration directory",
    "text": "1.2 Step 1. Choose a canonical R configuration directory\nDecide on a single folder that will store your personal R configuration files.\nWe recommend creating a dedicated folder at the root of your working directory, for example:\nC:\\WBG\\R\n\nInside that folder, you’ll have:\nC:\\WBG\\R.Renviron\nC:\\WBG\\R.Rprofile",
    "crumbs": [
      "R Setup and efficiency",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R, RStudio, and Positron to Use the Same Configuration Files</span>"
    ]
  },
  {
    "objectID": "setupR.html#step-2.-create-or-update-your-configuration-files",
    "href": "setupR.html#step-2.-create-or-update-your-configuration-files",
    "title": "1  Setting Up R, RStudio, and Positron to Use the Same Configuration Files",
    "section": "1.3 Step 2. Create (or update) your configuration files",
    "text": "1.3 Step 2. Create (or update) your configuration files\n\n1.3.1 .Renviron\nCreate a text file named .Renviron at C:\\WBG\\R\\.Renviron and add your preferred settings:\n# C:/WBG/R/.Renviron\nR_LIBS=C:/WBG/R/r-packages/%v\nR_USER=C:/WBG/R\nR_LIBS_USER=C:/WBG/R/r-packages/%v\nRENV_PATHS_LIBRARY_ROOT=C:/WBG/R/r-packages/.renv/library\nLANG=en_US.UTF-8\nTZ=UTC\nRENVIRON_LOADED_FROM=C:/WBG/R/.Renviron\nThis file defines environment variables that R reads at startup — for example, custom library locations, locale settings, or proxy credentials.\n\n\n1.3.2 .Rprofile\nCreate a text file named .Rprofile at C:\\WBG\\R\\.Rprofile and add the R code that should run automatically at startup:\n# C:/WBG/R/.Rprofile\nlocal({\n  r &lt;- getOption(\"repos\")\n  r[\"CRAN\"] &lt;- \"https://cran.rstudio.com/\"\n  options(repos = r)\n})\n\n# Optional: print which file was loaded (for debugging)\ncat(sprintf(\"[.Rprofile loaded from: %s]\\n\", normalizePath(sys.frame(1)$ofile, mustWork = FALSE)))",
    "crumbs": [
      "R Setup and efficiency",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R, RStudio, and Positron to Use the Same Configuration Files</span>"
    ]
  },
  {
    "objectID": "setupR.html#step-3.-tell-windows-and-r-where-to-find-these-files",
    "href": "setupR.html#step-3.-tell-windows-and-r-where-to-find-these-files",
    "title": "1  Setting Up R, RStudio, and Positron to Use the Same Configuration Files",
    "section": "1.4 Step 3. Tell Windows and R where to find these files",
    "text": "1.4 Step 3. Tell Windows and R where to find these files\nThe most reliable method is to set persistent user environment variables using setx, which works even in secure or constrained PowerShell environments (like corporate devices).\nOpen PowerShell or Command Prompt or Terminal in Vscode (no admin rights needed) and run:\nsetx R_ENVIRON_USER \"C:\\WBG\\R\\.Renviron\"\nsetx R_PROFILE_USER \"C:\\WBG\\R\\.Rprofile\"\nsetx HOME \"C:\\WBG\\R\"\nsetx R_USER \"C:\\WBG\\R\"\nThese commands instruct R to always look for .Renviron and .Rprofile in that directory, no matter which IDE you open.\nThen close and reopen RStudio, Positron, or any terminal using R.",
    "crumbs": [
      "R Setup and efficiency",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R, RStudio, and Positron to Use the Same Configuration Files</span>"
    ]
  },
  {
    "objectID": "setupR.html#step-4.-verify-the-configuration",
    "href": "setupR.html#step-4.-verify-the-configuration",
    "title": "1  Setting Up R, RStudio, and Positron to Use the Same Configuration Files",
    "section": "1.5 Step 4. Verify the configuration",
    "text": "1.5 Step 4. Verify the configuration\nAfter restarting R (in any IDE), run the following to confirm the setup:\npath.expand(\"~\")\nnormalizePath(\"~/.Renviron\", mustWork = FALSE)\nnormalizePath(\"~/.Rprofile\", mustWork = FALSE)\nSys.getenv(c(\"R_ENVIRON_USER\", \"R_PROFILE_USER\", \"R_LIBS_USER\", \"LANG\", \"TZ\"))\nExpected results:\n\n~ resolves to C:/WBG/R\n.Renviron and .Rprofile point to the same files in that folder\nYour environment variables (R_LIBS_USER, etc.) are correctly loaded",
    "crumbs": [
      "R Setup and efficiency",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R, RStudio, and Positron to Use the Same Configuration Files</span>"
    ]
  },
  {
    "objectID": "setupR.html#step-5.-optional-cleanup",
    "href": "setupR.html#step-5.-optional-cleanup",
    "title": "1  Setting Up R, RStudio, and Positron to Use the Same Configuration Files",
    "section": "1.6 Step 5. Optional cleanup",
    "text": "1.6 Step 5. Optional cleanup\nIf you previously had .Rprofile files in other locations (like your Documents or OneDrive folder), remove or rename them by adding a .bak at the end (e.g., .Rprofile.bak). R automatically runs the first .Rprofile it finds, so duplicate files can cause confusion or run twice.\nBy following this setup, your R environment becomes predictable, portable, and IDE-agnostic — a professional-grade configuration for serious R development.",
    "crumbs": [
      "R Setup and efficiency",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R, RStudio, and Positron to Use the Same Configuration Files</span>"
    ]
  },
  {
    "objectID": "VScode_Setup_for_stata.html",
    "href": "VScode_Setup_for_stata.html",
    "title": "2  SetUp Vscode to work with Stata",
    "section": "",
    "text": "2.1 Install VScode and Stata Extensions",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SetUp Vscode to work with Stata</span>"
    ]
  },
  {
    "objectID": "VScode_Setup_for_stata.html#install-vscode-and-stata-extensions",
    "href": "VScode_Setup_for_stata.html#install-vscode-and-stata-extensions",
    "title": "2  SetUp Vscode to work with Stata",
    "section": "",
    "text": "Open “Company Portal” app on your computer.\nSearch for VS Code and install it.(Make sure Git Credential Manager is selected)\nSearch for GitForWindows and install it.\nOpen VS Code → Extensions (left sidebar), and install:\n\nStata Enhanced (syntax highlighting).\nGit Graph (visualize branches).\nGitLens (blame/insight).\nGitHub Pull Requests and Issues.\nGitHub Copilot (optional).\nGitHub Copilot Chat (optional).",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SetUp Vscode to work with Stata</span>"
    ]
  },
  {
    "objectID": "VScode_Setup_for_stata.html#configure-rundo-and-rundolines",
    "href": "VScode_Setup_for_stata.html#configure-rundo-and-rundolines",
    "title": "2  SetUp Vscode to work with Stata",
    "section": "2.2 Configure rundo and rundolines",
    "text": "2.2 Configure rundo and rundolines\nAll the information in this section is based on Friedrich Huebler’s article. If you need more detail, see his blog.\n\nFor convenience, we also mirror the files here: https://github.com/GPID-WB/Pip-Technical-Guidelines/raw/refs/heads/main/_data/rundofiles.zip\nExtract the ZIP into C:\\ado\\personal. You’ll see six files; you only need to modify two of them:\n\nrundo.ini\nrundolines.ini\n\nOpen rundo.ini and rundolines.ini and set:\n\nstatapath → full path to your Stata EXE, e.g.: statapath = \"C:\\Program Files\\Stata19\\StataMP-64.exe\"\nstatawin → exact Stata window title, e.g.: statawin  = \"StataNow/MP 19.5\" \nstatacmd → shortcut that focuses Stata’s Command window (default is ^1 = Ctrl+1).\n\nThe two INIs should be identical except for the filename. Keep both updated.\n\n\n2.2.1 Recommended .ini tuning (for snappier runs)\nThese delays are safe and faster than the defaults:\n[Delays]\nclippause = 60   ; ms after copying selection to clipboard (40–80 is a good range)\nwinpause  = 120  ; ms between window ops (80–140 is a good range)\nkeypause  = 0    ; ms between keystrokes to Stata\nIf you ever get a “nothing happened” run, bump winpause up by ~20–40 ms.\nChecklist\n\nMake sure the window title matches exactly (minor version changes matter).\nKeep Stata open before your first send (cold attaches are slower).",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SetUp Vscode to work with Stata</span>"
    ]
  },
  {
    "objectID": "VScode_Setup_for_stata.html#set-up-user-tasks-global-once-to-call-rundolines-rundo",
    "href": "VScode_Setup_for_stata.html#set-up-user-tasks-global-once-to-call-rundolines-rundo",
    "title": "2  SetUp Vscode to work with Stata",
    "section": "2.3 Set up User Tasks (global, once) to call rundolines / rundo",
    "text": "2.3 Set up User Tasks (global, once) to call rundolines / rundo\n\nWe use User Tasks so you don’t have to repeat this per workspace.\n\n\nOpen Command Palette (Ctrl+Shift+P) → type: Tasks: Open User Tasks.\nPaste this JSON (adjust paths to match your machine). NOTE:\n\n\nUse double backslashes \\\\ in paths.\nIf \"tasks\" already exists, just add the two task objects inside the array.\n\n{\n  \"version\": \"2.0.0\",\n  \"tasks\": [\n    {\n      \"label\": \"Stata: Run selection/line (rundolines)\",\n      \"type\": \"shell\",\n      \"command\": \"\\\"C:\\\\ado\\\\personal\\\\rundolines.exe\\\"\",\n      \"presentation\": {\n        \"focus\": false,\n        \"panel\": \"dedicated\",\n        \"showReuseMessage\": false\n      }\n    },\n    {\n      \"label\": \"Stata: Do current file (rundo)\",\n      \"type\": \"shell\",\n      \"command\": \"\\\"C:\\\\ado\\\\personal\\\\rundo.exe\\\"\",\n      \"args\": [\"\\\"${file}\\\"\"],\n      \"presentation\": {\n        \"focus\": false,\n        \"panel\": \"dedicated\",\n        \"showReuseMessage\": false\n      }\n    }\n  ]\n}\n\nrundolines sends the current selection (or current line if nothing is selected).\nrundo runs the entire file (saves first).",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SetUp Vscode to work with Stata</span>"
    ]
  },
  {
    "objectID": "VScode_Setup_for_stata.html#bind-your-keyboard-shortcuts-global-once",
    "href": "VScode_Setup_for_stata.html#bind-your-keyboard-shortcuts-global-once",
    "title": "2  SetUp Vscode to work with Stata",
    "section": "2.4 Bind your keyboard shortcuts (global, once)",
    "text": "2.4 Bind your keyboard shortcuts (global, once)\n\nOpen Command Palette (Ctrl+Shift+P) → type: Keyboard Shortcuts → select: Open Keyboard Shortcuts (JSON).\nAdd (or adapt keys if you already use F9/F10 or if you don’t want to use F9/F10):\nHoubler suggests not use any shortcut with the key Ctrl as it may get “stuck”.\n\n[\n  {\n    \"key\": \"f9\",\n    \"command\": \"workbench.action.tasks.runTask\",\n    \"args\": \"Stata: Run selection/line (rundolines)\",\n    \"when\": \"editorTextFocus && (resourceExtname =~ /\\\\.(do|ado|mata)$/ || (resourceScheme == 'untitled' && editorLangId == 'stata'))\"\n  },\n  {\n    \"key\": \"f10\",\n    \"command\": \"workbench.action.tasks.runTask\",\n    \"args\": \"Stata: Do current file (rundo)\",\n    \"when\": \"editorTextFocus && (resourceExtname =~ /\\\\.(do|ado|mata)$/ || (resourceScheme == 'untitled' && editorLangId == 'stata'))\"\n  }\n]\n\nThe when clauses limit these keys to Stata files.\nIf you already mapped F9/F10 to something else, either change those or pick different keys (e.g., f8 / f9).\n\n\nTip: If you still have Code Runner installed, remove any bindings that clash (search “Run Code” in Keyboard Shortcuts and delete its keybindings). You can also disable/uninstall Code Runner entirely—you don’t need it.",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SetUp Vscode to work with Stata</span>"
    ]
  },
  {
    "objectID": "VScode_Setup_for_stata.html#optional-running-mata-files-directly",
    "href": "VScode_Setup_for_stata.html#optional-running-mata-files-directly",
    "title": "2  SetUp Vscode to work with Stata",
    "section": "2.5 (Optional) Running Mata files directly",
    "text": "2.5 (Optional) Running Mata files directly\nTwo clean options; pick one.\n\n2.5.1 A) Wrapper .do (recommended for standalone .mata files)\nCreate .vscode/_run_mata.do in your repo (or anywhere stable):\n// _run_mata.do\nargs mfile\nmata:\nmata clear\nmata do \"`mfile'\"\nend\nAdd a User Task to invoke it with the current file:\n{\n  \"label\": \"Stata: Mata do current file\",\n  \"type\": \"shell\",\n  \"command\": \"\\\"C:\\\\Program Files\\\\Stata19\\\\StataMP-64.exe\\\"\",\n  \"args\": [\"/e\", \"do\", \"\\\"${workspaceFolder}\\\\.vscode\\\\_run_mata.do\\\"\", \"\\\"${file}\\\"\"]\n}\nAnd a keybinding for .mata files:\n{\n  \"key\": \"f8\",\n  \"command\": \"workbench.action.tasks.runTask\",\n  \"args\": \"Stata: Mata do current file\",\n  \"when\": \"editorTextFocus && (resourceExtname =~ /\\\\.(mata)$/)\"\n}\n\n\n2.5.2 B) Mata blocks inside a .do\nPlace your Mata code inside a mata: … end block in a .do, then use F9 (selection) or F10 (whole file).",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SetUp Vscode to work with Stata</span>"
    ]
  },
  {
    "objectID": "VScode_Setup_for_stata.html#quick-sanity-test-30-seconds",
    "href": "VScode_Setup_for_stata.html#quick-sanity-test-30-seconds",
    "title": "2  SetUp Vscode to work with Stata",
    "section": "2.6 Quick sanity test (30 seconds)",
    "text": "2.6 Quick sanity test (30 seconds)\n\nOpen a .do. Type and select:\ndisplay \"hello from VS Code\"\nPress F9 → Stata should execute the selection.\nPress F10 → Stata should run the entire file.\n\nIf nothing happens, check:\n\nTasks names match your keybinding args exactly.\nYou edited User Tasks (not workspace .vscode/tasks.json).\nNo conflicting keybinding is intercepting F9/F10.",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SetUp Vscode to work with Stata</span>"
    ]
  },
  {
    "objectID": "VScode_Setup_for_stata.html#troubleshooting-performance",
    "href": "VScode_Setup_for_stata.html#troubleshooting-performance",
    "title": "2  SetUp Vscode to work with Stata",
    "section": "2.7 Troubleshooting & Performance",
    "text": "2.7 Troubleshooting & Performance\n\nFirst run is slower (1–3 s) due to task runner warm-up and first attach. Subsequent runs are often sub-second with tuned INIs.\nIf sends are flaky, raise winpause slightly (e.g., from 120 → 140 ms).\nVerify statawin matches the exact window title (minor versions matter).\nKeep Stata open; cold-launches add seconds.\nAvoid network paths for ado/working dirs when possible.\nConsider AV exclusions for the Stata EXE, rundolines.exe, rundo.exe, and your ado/workspace.",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SetUp Vscode to work with Stata</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html",
    "href": "VScode_setup_for_github.html",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "",
    "text": "3.1 Prerequisites",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#prerequisites",
    "href": "VScode_setup_for_github.html#prerequisites",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "",
    "text": "Git for Windows installed (includes Git Credential Manager).\nVS Code installed.\nMake sure you’re added to the World Bank GitHub organization using eservices/ request.",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#install-vscode-and-stata-extensions",
    "href": "VScode_setup_for_github.html#install-vscode-and-stata-extensions",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "3.2 Install VScode and Stata Extensions",
    "text": "3.2 Install VScode and Stata Extensions\n\nOpen “Company Portal” app on your computer.\nSearch for VS Code and install it.\nSearch for GitForWindows and install it. (Make sure Git Credential Manager is selected)\nOpen VS Code → Extensions (left sidebar), and install:\n\nStata Enhanced (syntax highlighting).\nGit Graph (visualize branches).\nGitLens (blame/insight).\nGitHub Pull Requests and Issues.\nGitHub Copilot (optional).\nGitHub Copilot Chat (optional).",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#first-time-git-configuration-one-time",
    "href": "VScode_setup_for_github.html#first-time-git-configuration-one-time",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "3.3 First-time Git configuration (one-time)",
    "text": "3.3 First-time Git configuration (one-time)\nOpen Terminal in VS Code (Ctrl+`) and run:\n# Identify yourself in commits\ngit config --global user.name  \"Your Name\"\ngit config --global user.email \"your_email@domain.com\"\n\n# Use main as default branch for new repos\ngit config --global init.defaultBranch main\n\n# Line endings: recommended on Windows\ngit config --global core.autocrlf true  # checkout CRLF, commit LF\n\n# Improve diffs for common texty files\ngit config --global diff.renameLimit 99999\ngit config --global fetch.prune true",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#authenticate-to-github",
    "href": "VScode_setup_for_github.html#authenticate-to-github",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "3.4 Authenticate to GitHub",
    "text": "3.4 Authenticate to GitHub\nGo to your profile on VScode and login to GitHub.\nTrying to clone/push over HTTPS will trigger a secure web flow:\n\nUse a GitHub personal access token (PAT) or organization SSO as prompted.\nGit Credential Manager securely stores/refreshes credentials.",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#clone-or-publish-a-repository-in-vs-code",
    "href": "VScode_setup_for_github.html#clone-or-publish-a-repository-in-vs-code",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "3.5 Clone or publish a repository in VS Code",
    "text": "3.5 Clone or publish a repository in VS Code\n\n3.5.1 Clone an existing repository\n\nCommand Palette → Git: Clone → paste repo URL (HTTPS or SSH).\nChoose a local folder → VS Code offers to open the folder.\n\n\n\n3.5.2 Publish (create a new GitHub repo from a local folder)\n\nOpen your project folder in VS Code.\nSource Control view → Initialize Repository.\nCommit initial files.\nClick Publish to GitHub (or run Command Palette → Publish to GitHub).\n\nChoose a name, visibility (private/public), and org/user.",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#power-ups",
    "href": "VScode_setup_for_github.html#power-ups",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "3.6 Power-ups",
    "text": "3.6 Power-ups\n\n3.6.1 GitLens highlights\n\nInline blame (who/when changed this line)\nFile & line history with rich diffs\nVisualize & compare branches; open Repositories view\nOpen PR associated with a line/commit\nCode authorship heatmaps and commit search by message, author, time\n\n\n\n3.6.2 Git Graph highlights\n\nGraph view of all branches/tags\nDrag & drop merges/rebases (careful: follow team policy)\nQuick reset, cherry-pick, revert from context menu\n\n\n\n3.6.3 Copilot & Copilot Chat\nIn order to access Copilot and Copilot Chat, You need to be added to the World Bank GitHub organization using eservices/ request.\nMake sure you read the Getting Started Guide with GIthub Copilot.\nAlso, make sure you understand and follow the instructions in the General Github Copilot Usage Policy and guide.\n\nCopilot inline suggestions: code, tests, small refactors\nCopilot Chat for:\n\n“Explain this diff” / “Write a PR description”\n“Generate a .gitignore for Stata + VS Code”\n“Draft a release note from merged PRs since vX.Y”",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#team-conventions-recommended",
    "href": "VScode_setup_for_github.html#team-conventions-recommended",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "3.7 Team conventions (recommended)",
    "text": "3.7 Team conventions (recommended)\n\nBranching: feature branches from main; short, descriptive names.\nCommits: small, frequent, imperative subject line; reference issues (#123).\nPRs: clear description (what/why), checklist, reviewers; keep PRs small.\nMerging: prefer squash to keep history clean (unless you need merge commits).\nCI: make PR green before merge; don’t push directly to main.",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#quick-reference-commands",
    "href": "VScode_setup_for_github.html#quick-reference-commands",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "3.8 Quick reference (commands)",
    "text": "3.8 Quick reference (commands)\n# Start a repo\ngit init\ngit add .\ngit commit -m \"Initial commit\"\ngit branch -M main\ngit remote add origin &lt;ssh-or-https-url&gt;\ngit push -u origin main\n\n# Typical feature flow\ngit checkout -b feature/my-change\n# ...edit...\ngit add -A\ngit commit -m \"Implement my change\"\ngit push -u origin feature/my-change\n# open PR in VS Code (GitHub PRs extension)\n\n# Sync main\ngit checkout main\ngit pull --ff-only",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "VScode_setup_for_github.html#suggested-vs-code-settings-optional",
    "href": "VScode_setup_for_github.html#suggested-vs-code-settings-optional",
    "title": "3  SetUp Git & GitHub in VS Code",
    "section": "3.9 Suggested VS Code settings (optional)",
    "text": "3.9 Suggested VS Code settings (optional)\nCreate .vscode/settings.json in your repo to nudge consistent behavior:\n{\n  \"git.enableSmartCommit\": true,\n  \"git.confirmSync\": false,\n  \"git.autofetch\": true,\n  \"git.openRepositoryInParentFolders\": \"always\",\n  \"files.eol\": \"\\n\",\n  \"editor.renderWhitespace\": \"boundary\",\n  \"editor.rulers\": [100],\n  \"diffEditor.ignoreTrimWhitespace\": false\n}",
    "crumbs": [
      "VSCode Setup",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>SetUp Git & GitHub in VS Code</span>"
    ]
  },
  {
    "objectID": "copilot_protocols.html",
    "href": "copilot_protocols.html",
    "title": "4  Mandatory Protocols for Using GitHub Copilot in Technical Work",
    "section": "",
    "text": "4.1 Purpose and Principles\nGitHub Copilot is a powerful assistant that can increase productivity, generate boilerplate code quickly, and support experimentation. However, Copilot is not a substitute for engineering judgment, critical thinking, or expertise in R/Stata. Without discipline, Copilot can also introduce inefficiency, unnecessary complexity, hallucinated dependencies, and silent errors. This document establishes:\nTeam leads will verify compliance during code reviews.",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Mandatory Protocols for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_protocols.html#purpose-and-principles",
    "href": "copilot_protocols.html#purpose-and-principles",
    "title": "4  Mandatory Protocols for Using GitHub Copilot in Technical Work",
    "section": "",
    "text": "Mandatory protocols for how Copilot must be used in all GPID technical work.\n\nA unified system of Copilot prompt files, named gpid-proto-*, which encode these protocols into reproducible steps.\n\nClear instructions on how to install, update, and use these prompt files across all GPID projects.",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Mandatory Protocols for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_protocols.html#gpid-copilot-prompt-system",
    "href": "copilot_protocols.html#gpid-copilot-prompt-system",
    "title": "4  Mandatory Protocols for Using GitHub Copilot in Technical Work",
    "section": "4.2 GPID Copilot Prompt System",
    "text": "4.2 GPID Copilot Prompt System\nTo ensure consistency, the GPID team uses shared Github Copilot prompt files stored in a central repository. These prompt files automate the workflows described in this document.\n\n4.2.1 What Are GPID Prompt Files?\nPrompt files are .prompt.md files that define reusable Github Copilot commands.\nThey appear in VS Code or Positron when you type / in Github Copilot Chat.\nEach GPID protocol prompt begins with the prefix gpid-proto-\nExamples:\n\n/gpid-proto-start-task\n\n/gpid-proto-explain-code\n\n/gpid-proto-document-code\n\n/gpid-proto-review-efficiency\n\n/gpid-proto-tests-checklist\n\n/gpid-proto-deps-risk\n\n/gpid-proto-self-critique\n\n/gpid-proto-wrap-task\n\nThese commands help you follow the mandatory protocols with minimal effort.\n\n\n4.2.2 Where the Prompt Files Live\nThe shared prompts are stored in the repository GPID-WB/copilot-prompts. The prompt files for these protocols are in the folder prompts/\nprompts/\ngpid-proto-start-task.prompt.md\ngpid-proto-explain-code.prompt.md\ngpid-proto-document-code.prompt.md\ngpid-proto-review-efficiency.prompt.md\ngpid-proto-tests-checklist.prompt.md\ngpid-proto-deps-risk.prompt.md\ngpid-proto-self-critique.prompt.md\ngpid-proto-wrap-task.prompt.md\n\nThese prompts are global tools used in every GPID technical project.\n\n\n4.2.3 One-Time Installation (Per Developer)\nEach team member must clone the prompts repository locally. For the rest of this document, we assume you clone it to:\nC:\\Users\\&lt;USERNAME&gt;\\OneDrive - WBG\\GPID-team\\copilot-prompts\n\n\n4.2.4 Registering Prompt Files in VS Code / Positron\nAfter cloning, you must tell Github Copilot where to find the shared prompts by modifying the user settings. This can by done in multiple ways, but we recommend the following:\n\nIn VS Code/Positron, open settings via the gear icon in the lower left corner or by hitting Ctrl + ,.\nSearch for “prompt files location” (without quotes).\nHit “add item” and add the full path to the prompts folder in your local clone of the repository adding the protocols/ subfolder. \nRestart VS Code/Positron.\n\nNOW: Typing / in Github Copilot Chat will show all GPID protocol prompts.\n\n\n4.2.5 Updating Prompt Files\nWhenever a prompt file changes, you will be notified. However, the best practice is to regularly update your local copy. You can do it by opening the copilot-prompts folder in a terminal and running git pull, opening the whole folder in Positron and VScode and sync the changes or by using script similar to this:\ncd \"C:\\Users\\USERNAME\\OneDrive - WBG\\GPID-team\\copilot-prompts\"\ngit pull",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Mandatory Protocols for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_protocols.html#the-gpid-protocol-prompts",
    "href": "copilot_protocols.html#the-gpid-protocol-prompts",
    "title": "4  Mandatory Protocols for Using GitHub Copilot in Technical Work",
    "section": "4.3 The GPID Protocol Prompts",
    "text": "4.3 The GPID Protocol Prompts\nThe following sections describe each mandatory protocol and the corresponding gpid-proto-* prompt that should be used.\nUsing the prompts is simple. You just need to type the prompt command in Github Copilot Chat.\nExample:\n/gpid-proto-start-task\nGithub Copilot will ask for the necessary information and then guide you through the protocol.\n\nProtocol 1 — Documenting Your Work With Github Copilot\nPrompt:\n/gpid-proto-start-task\n\nPurpose\nEvery Copilot-assisted task must produce a clear, transparent trail of:\n\nWhat was done\nWhy decisions were made\nWhat dependencies were added or removed\nHow the final code works\n\n\n\nWhat It Does\nWhen you run /gpid-proto-start-task, Github Copilot:\n\nAsks you for:\n\nTask name\nShort description\n\nLogs these clearly and begins a running summary of:\n\nkey prompts\nmajor decisions\nassumptions\ndependencies added/removed\n\nKeeps the summary alive throughout the task.\n\nYou do not need to structure this manually — the prompt enforces consistency.\n\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-proto-start-task\n\n\n\n\n\nYou are assisting a World Bank technical team (R + Stata) following strict Copilot protocols.\nWe are starting a new Copilot-assisted task.\nFollow this protocol:\n\nAsk me for:\n\na short task name (TASK_NAME)\na one-sentence description of the task (TASK_DESCRIPTION)\n\nOnce I answer, restate both clearly, but do not try to solve the task yet. Use this format:\n\nTask name: ...\nDescription: ...\n\nFrom that point on, keep a concise running summary of our interaction, including:\n\nmajor prompts I send\nimportant decisions we make\ndependencies added or removed\nassumptions or limitations we identify\n\nDo not generate the final report yet.\nYour role after the initial questions is, only when asked, to:\n\nclarify ambiguities\nhelp design the approach\ngenerate and refine code/tests according to our protocols.\n\n\nAssume that at the end of the task I will call another prompt (/wrap-task) to generate the final Markdown summary under copilot_logs/TASK_NAME.md.\n\n\n\n\n\n\n\nProtocol 2 — Making the Code Understandable\nPrompts:\n/gpid-proto-explain-code\n/gpid-proto-document-code\n\nPurpose\nGithub Copilot may generate correct code, but not always readable code. These prompts ensure that the logic, intention, and structure are thoroughly documented.\n\n\nWhat They Do\n\n/gpid-proto-explain-code\n\nAsks what function/file you want explained\nProduces a step-by-step technical explanation\nLists assumptions\nIdentifies failure points\n\n\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-proto-explain-code\n\n\n\n\n\nYou will be asked to explain a function, test file, or script (usually R or Stata).\nIf the context is ambiguous, first ask me what code or file you should focus on (e.g., current selection, specific function, or file).\nThen follow this protocol:\n\nHigh-level overview\n\nIn 3–5 sentences, explain what the code does conceptually.\n\nStep-by-step explanation\n\nWalk through the major blocks of the code.\nFocus on logic and structure rather than line-by-line commentary.\n\nAssumptions\n\nExplicitly list assumptions about:\n\ninput types, shapes, and ranges\nrequired columns / variables\nexpected data structure (e.g., data.table, Stata dataset)\nexternal dependencies or files\n\n\nFailure points\n\nIdentify where the code might break or behave incorrectly:\n\nmissing or malformed inputs\nedge cases (empty data, small N, extreme values)\nperformance pitfalls on large data\n\n\n\nReturn your explanation in clean Markdown with headings:\n\nHigh-level overview\n\nStep-by-step explanation\n\nAssumptions\n\nPotential failure points\n\nThis text should be ready to paste into the task summary.\n\n\n\n\n\n/gpid-proto-document-code\n\nAdds in-code comments (the “what” and the “why”)\nAdds full Roxygen2 documentation (for R code)\nProduces a plain-language explanation for the task summary\n\n\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-proto-document-code\n\n\n\n\n\nYou will be given one or more functions or scripts, mainly in R (often using data.table, collapse, rlang) and sometimes Stata.\nIf it is unclear what code to document, first ask me which function/file/selection to use.\nThen follow this protocol:\n\nIn-code comments\n\nAdd clear, human-readable comments that explain:\n\nwhat each major block does\nwhy this approach or pattern is appropriate\nimportant trade-offs or design decisions\n\nAvoid trivial “this line adds 1” comments. Focus on intent.\n\nRoxygen2 (for R functions)\n\nFor each relevant R function, add or update:\n\n@title\n@description\n@param\n@return\n@examples (when helpful and not trivial)\n@import / @importFrom only when truly needed.\n\nPrefer our usual stack (data.table, collapse, rlang) when appropriate.\n\nPlain-language explanation\n\nAt the end, write a short, plain-language explanation of how the main function(s) work, suitable for a teammate reading them for the first time.\n\n\nReturn: 1. The updated code (with comments and Roxygen2 tags).\n2. The plain-language explanation as a separate Markdown section that can be added to the task summary.\n\n\n\n\n\n\n\n\nProtocol 3 — Code Review and Efficiency Check\nPrompt:\n/gpid-proto-review-efficiency\n\nPurpose\nBefore testing, every piece of Copilot-generated code must undergo an efficiency audit.\n\n\nWhat It Does\nThe prompt reviews code for:\n\nredundant logic\nunnecessary copies\nover-nested structures\nunused variables\ndependency creep\noverly complex or fragile patterns\n\nAnd provides clear, actionable improvements.\n\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-proto-review-efficiency\n\n\n\n\n\nYou are reviewing Copilot-assisted code for efficiency, simplicity, and maintainability.\nIf it is unclear what to review, first ask me which function/file/selection to analyze.\nThen:\n\nScan for inefficiencies\n\nredundant or duplicated logic\nunnecessary copies of large objects\nloops that could be vectorized or replaced by data.table / collapse operations\ndeeply nested if/else or loops that could be simplified\n\nFind unused or dead code\n\nunused variables\nunreachable logic\nold commented-out or experimental blocks that should be removed\n\nCheck dependencies\n\nidentify new or heavy dependencies\nsuggest removing or replacing packages that are not truly needed\nprefer our established stack when reasonable\n\nPropose concrete improvements For each issue:\n\ndescribe the problem\npropose a specific improvement\nbriefly explain why it matters (performance, clarity, maintainability, robustness)\n\n\nReturn a structured Markdown report with headings like: - Inefficiencies\n- Unnecessary complexity\n- Dead or unused code\n- Dependency issues\n- Recommended improvements\n\n\n\n\n\n\n\nProtocol 4 — Testing and Edge Cases\nPrompt:\n/gpid-proto-tests-checklist\n\nPurpose\nNo Copilot-generated code is accepted without thorough testing.\n\n\nWhat It does\n\nA validation checklist\ntestthat unit tests (for R)\nStata assertions (if needed)\nOptional performance tests\n\nAll structured for direct inclusion in your PR.\n\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-proto-tests-checklist\n\n\n\n\n\nYou will help design validation for a function, module, or script.\nIf it is unclear what to validate, first ask me which function/file/selection to focus on.\nThen follow this protocol:\n\nValidation checklist\n\nList:\n\nexpected inputs and outputs\nrequired dependencies\nmain assumptions\npotential failure points\nedge cases that must be tested\n\n\nR unit tests (testthat)\n\nWhen the code is in R, generate testthat tests that cover:\n\nnormal cases\nedge cases\nwrong input types\nmissing values\nextreme or unusual data scenarios\n\n\nStata tests\n\nWhen the code is in Stata, generate a do-file with assertions/checks for:\n\nrealistic data\ncorner cases\nunexpected or malformed inputs\n\n\nPerformance-sensitive checks (optional)\n\nIf the code is performance-critical or uses large data, propose tests that:\n\nstress memory usage\nexpose slow operations or unnecessary copies\n\n\n\nReturn: - the validation checklist (Markdown)\n- the test code (R testthat or Stata do-file) ready to be added to the repository\n\n\n\n\n\n\n\nProtocol 5 — Dependencies, Risks, and Safety\nPrompt:\n/gpid-proto-deps-risk\n\nPurpose\nEnsure that dependencies are justified, safe, and aligned with team standards.\n\n\nWhat It Does\n\nLists all dependencies\nExplains why each is needed\nFlags unnecessary packages\nChecks compatibility with data.table, collapse, and rlang\nIdentifies unsafe patterns (I/O, file paths, etc.)\n\n\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-proto-deps-risk\n\n\n\n\n\nYou are reviewing dependencies and risks for Copilot-assisted code in R or Stata.\nIf it is unclear what code to inspect, ask me which file/selection to analyze.\nThen:\n\nDependency analysis\n\nList all external packages/dependencies used or introduced.\nFor each, explain briefly why it is needed.\nIdentify dependencies that are:\n\nunnecessary\noverlapping/redundant\nheavier than needed for the task\n\nSuggest simplifications or removals where possible.\n\nCompatibility with our preferred stack (R)\n\nCheck for conflicts or unnecessary overlaps with:\n\ndata.table\ncollapse\nrlang\n\nWhen reasonable, suggest implementations that better fit this stack.\n\nSecurity and stability\n\nFlag any:\n\nunsafe file I/O patterns\nhard-coded paths, credentials, or URLs\nfragile assumptions about external systems or files\n\nProvide concrete suggestions to mitigate each risk.\n\n\nReturn findings in Markdown with sections: - Dependencies and justification\n- Opportunities to simplify dependencies\n- Compatibility with preferred stack\n- Security and stability concerns\n- Recommended mitigations\n\n\n\n\n\n\n\nProtocol 6 — Self-Critique and Robustness Review\nPrompt:\n/gpid-proto-self-critique\n\nPurpose\nGithub Copilot is surprisingly good at critiquing its own work when prompted correctly.\nThis step often finds issues humans miss.\n\n\nWhat It Does\n\nReviews code as if performing a formal code review\nIdentifies inefficiencies\nPoints out risky assumptions\nSuggests simplifications\nProduces a concise summary of strengths, risks, and recommended improvements\n\n\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-proto-self-critique\n\n\n\n\n\nYou are performing a self-critique of Copilot-assisted code, as if you were a human reviewer.\nIf it is unclear what code to review, first ask me which function/file/selection to critique.\nThen:\n\nIdentify inefficiencies\n\nredundant code\nunnecessary work\npoor data handling\noperations that will be slow or memory-heavy on large data\n\nComplexity issues\n\nover-nested logic\nconfusing control flow\nunneeded abstractions or indirection\n\nRisky assumptions\n\nfragile expectations about inputs\npoor handling of NA/missing values\nedge cases likely to break the code\n\nOpportunities to use our preferred stack\n\nplaces where data.table, collapse, or rlang (in R) would lead to clearer or more efficient code, when appropriate for the project.\n\nConcrete improvements\n\nFor each issue:\n\ndescribe the problem\npropose a specific improvement\nexplain its impact (performance, readability, robustness, maintainability)\n\n\n\nEnd with a short summary: - Key strengths\n- Key risks\n- Top 3 improvements to implement next\n\n\n\n\n\n\n\nProtocol 7 — Producing the Final Validation Bundle\nPrompt:\n/gpid-proto-wrap-task TASK_NAME\n\nPurpose\nEvery Copilot-assisted task ends with a final Markdown summary stored under:\ncopilot_logs/TASK_NAME.md\n\n\nWhat It Does\n\nTask overview\nStep-by-step technical explanation\nPlain-language overview\nIn-code comments summary\nRoxygen2 documentation summary\nValidation checklist\nUnit tests and edge cases\nError-handling strategy\nDependency and risk analysis\nSelf-critique findings\nRemaining TODOs\n\nThis file must always be included in your PR.\n\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-proto-wrap-task\n\n\n\n\n\nWe have reached the end of a Copilot-assisted task.\nThe task name is: **\\({input}**\nUse this as `TASK_NAME` (for example in `copilot_logs/\\){input}.md`).\nUsing our full conversation and your running summary, generate a Markdown report suitable for saving as copilot_logs/TASK_NAME.md. Include:\n\nTask overview\n\nwhat the task was about\nmain files/functions affected\nmajor decisions and trade-offs\n\nTechnical explanation\n\nstep-by-step description of how the code works\nimportant algorithmic or design choices\nany performance considerations\n\nPlain-language overview\n\nwhy the code exists\nhow a teammate should use it\nnon-technical explanation of the behavior\n\nDocumentation and comments\n\nconfirmation of in-code comments and Roxygen2 docs (for R)\nany important notes for future maintainers\n\nValidation bundle\n\nvalidation checklist\nunit tests and edge cases (summarize what is covered)\nerror-handling strategy (how invalid or unexpected inputs are handled)\nperformance-sensitive tests, if applicable\n\nDependencies and risk analysis\n\nsummary of dependency decisions\nkey security/stability considerations\n\nSelf-critique and follow-ups\n\nmain issues uncovered by reviews/self-critique\nremaining TODOs or recommended future improvements\n\n\nReturn only the Markdown document, and save it as copilot_logs/${input}.md.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you’re working in an R package, make sure to include the copilot_logs folder in your .Rbuildignore file to prevent it from being included in the package build.\nYou can do it by\n\nexecuting usethis::use_build_ignore(\"copilot_logs\") or,\nby manually adding the line ^copilot_logs/$ to the .Rbuildignore file.",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Mandatory Protocols for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_protocols.html#final-reminder-you-are-the-author",
    "href": "copilot_protocols.html#final-reminder-you-are-the-author",
    "title": "4  Mandatory Protocols for Using GitHub Copilot in Technical Work",
    "section": "4.4 Final Reminder: You Are the Author",
    "text": "4.4 Final Reminder: You Are the Author\nThe code produced by Github Copilot is ultimately your responsibility.\n• Authorship means accountability: When you commit Copilot-assisted code, you are claiming authorship of it. This means you’re responsible for its correctness, efficiency, and maintainability.\n• Review is mandatory: Skipping the efficiency review puts the burden on your teammates during code review, slows down development, and can introduce bugs or performance issues that are hard to trace later.\n• Use Github Copilot as a tool, not a replacement: Github Copilot accelerates your work, but it cannot replace your engineering judgment. You must understand, evaluate, and refine everything it produces.\nBottom line: If you wouldn’t put your name on it as-is, don’t commit it yet. Clean it up first.",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Mandatory Protocols for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_guidelines.html",
    "href": "copilot_guidelines.html",
    "title": "Suggested Guidelines for Using GitHub Copilot in Technical Work",
    "section": "",
    "text": "Purpose and Principles\nGitHub Copilot is a powerful tool that can accelerate development, help you explore solutions, and reduce repetitive coding tasks. However, it works best when you know how to communicate effectively with it and when you maintain critical judgment about its suggestions.\nThis document provides suggested guidelines (not mandatory protocols) for using Copilot more effectively. These tips are designed to help you:\nThese guidelines complement the mandatory protocols outlined in the Copilot Protocols document. While protocols define what you must do for code reviews and formal tasks, these guidelines help you work more efficiently day-to-day.\nWe will suggest some prompts to apply this guidelines but feel free to modified them as needed to fit your specific context and projects.",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suggested Guidelines for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_guidelines.html#purpose-and-principles",
    "href": "copilot_guidelines.html#purpose-and-principles",
    "title": "Suggested Guidelines for Using GitHub Copilot in Technical Work",
    "section": "",
    "text": "Get better results faster — learn how to prompt Copilot effectively so you spend less time iterating.\nMaintain code quality — understand how to verify, refine, and improve Copilot’s suggestions.\nWork securely — avoid accidentally sharing sensitive data or introducing security risks.\nBuild reusable workflows — create prompt patterns you can share with teammates and reuse across projects.\nStay in control — use Copilot as an assistant, not a replacement for your engineering judgment.\n\n\n\n\nWhere the suggested Prompt Files Live\nThe shared prompts are stored in the repository GPID-WB/copilot-prompts. The prompt files for these guidelines are in the folder guidelines/.\nprompts/\ngpid-guide-complete-prompt.prompt.md\n\nTo include these prompts in your IDE, you can clone the repository and then import the relevant prompt files into your Copilot setup. See the installation instructions: One-Time Installation (Per Developer). Make sure to add the guidelines/ subfolder, as well as the protocols/ subfolder.\n\n\n\n\n\n\nTip\n\n\n\nThink of these guidelines as best practices that will save you time and help you get the most value from Copilot without compromising quality or security.",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suggested Guidelines for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_guidelines.html#prompt-engineering",
    "href": "copilot_guidelines.html#prompt-engineering",
    "title": "Suggested Guidelines for Using GitHub Copilot in Technical Work",
    "section": "Prompt engineering",
    "text": "Prompt engineering\nOne of the most important skills to develop when using Githup Copilot, or any other AI agent, is to know how to prompt. Github provides some guidelines on Prompt engineering for Github Copilot Chat, but here are the main points to take into consideration:\n\nStart general and then specific\nProvide examples\nBreak complex tasks into simpler tasks\nReread your prompt and avoid ambiguity\nIndicate relevant code (select a file or highlight the specific piece of code)\n\nExperiment and iterate until you find a useful answer\nKeep history relevant and delete requests that are not longer relevant\n\n\nThe Do’s and Don’ts when prompting\nUseful action verbs / short commands (with example sentences):\n\nAnalyze — “Analyze this function and list potential edge cases.”\nExplain — “Explain what this block of code does in plain language.”\nRefactor — “Refactor this function for readability and add comments.”\nTest — “Write unit tests for this function covering typical and edge cases.”\nSummarize — “Summarize the responsibilities of each module in one paragraph.”\nOptimize — “Optimize this loop for performance and explain changes.”\nValidate — “Validate input handling and add defensive checks.”\nSuggest — “Suggest alternative implementations that reduce memory usage.”\nDocument — “Add Roxygen2-style documentation for these functions.”\nCritique — “Critique this code and point out risks or unclear logic.”\n\nBest prompt structure (brief):\n\nContext: state which files, functions, or data the agent should consider.\nTask: give a clear action using a verb (from the list above).\nConstraints: list any requirements or restrictions (style, libraries, performance).\nExamples/output: show a small input/output example or the desired format for the answer.\n\n\n\n\n\n\n\nNoteExample\n\n\n\nContext: file utils.R (functions read_data, clean_data). Task: Write unit tests for clean_data. Constraints: use testthat, cover edge cases for NA and invalid types. Output: provide test code only.\n\n\nWhat to avoid when creating prompts:\n\nVague or ambiguous instructions (avoid “fix this” without context).\nOverloading a single prompt with many unrelated tasks.\nIncluding sensitive data (secrets, passwords, personal data).\nAssuming the agent knows private or internal project details not provided in the prompt.\nRequests that rely on unstated external state (unspecified files, databases, or services).\n\nNote on links and security: be cautious when including or following external links in prompts or Copilot responses—links may expose or lead to insecure resources and can present a security risk.\nPrompt suggested:\n/gpid-guide-complete-prompt\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-guide-complete-prompt\n\n\n\n\n\nYou are an expert coding assistant. For all tasks, make sure you have the necessary context and information. If any of the following are not provided, ask for them before proceeding.\n\nContext: {FILES_OR_SNIPPET}.\nTask: {SHORT_ACTION_VERB + target}.\nConstraints: {LIBRARIES, STYLE, PERFORMANCE, ETC.}.\nExample I/O: {GIVEN_INPUT =&gt; EXPECTED_OUTPUT}.\n\nAnd provide the following case example:\n“Context: file utils.R (read_data, clean_data). Task:”Write unit tests for clean_data”. Constraints: use testthat, cover NA and invalid types. Example I/O: “input: a vector with NA =&gt; expect: handled gracefully”.\nIf the user says to continue without the missing information, proceed with best-effort assumptions.\n\n\n\n\n\n\nSecurity Considerations for Prompts\nWhen creating prompts, follow these guidelines to protect organizational data and avoid security risks:\nNever include sensitive data: - Avoid pasting credentials, API keys, passwords, tokens, or authentication secrets. - Do not include personally identifiable information (PII) or confidential business data. - Exclude proprietary algorithms or internal business logic.\nSanitize code before sharing: - Remove or redact hardcoded secrets, connection strings, or environment variables. - Replace real identifiers with placeholders (e.g., &lt;DB_NAME&gt;, &lt;API_ENDPOINT&gt;). - Avoid exposing internal directory structures, server names, or infrastructure details.\nVerify external resources: - Do not blindly follow or execute code from links provided by Copilot. - Validate suggested packages, libraries, or URLs against trusted sources before installation. - Be aware that suggested resources may be outdated, compromised, or malicious.\nReview generated code: - Check for security vulnerabilities (SQL injection, command injection, unsafe file operations). - Verify that code follows secure coding practices (input validation, error handling, least privilege).\nKeep context minimal: - Only provide the minimum code/context necessary to answer your question. - Follow the organization’s data classification and handling policies.\nPrompt suggested:\n/gpid-guide-security\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-guide-security\n\n\n\n\n\nYou are a security-aware reviewer. Before using any provided context, ask the user to confirm that all sensitive data has been removed or redacted.\nBefore acting, prompt the user: “Please confirm that you have removed credentials, API keys, tokens, passwords, PII, and other private information. Reply ‘yes’ to continue or upload a redacted version.”\nUnder no circumstances should you ever output or recreate secrets, credentials, or other sensitive information. If a user asks to recover or reveal secrets, refuse and explain why.\nWhen code or links are provided:\n\nDo not execute external code or follow links automatically.\nValidate suggested packages/URLs conceptually and warn about untrusted or outdated sources.\nFlag potentially unsafe operations (e.g., file deletions, system calls, eval/exec, unescaped SQL) and request explicit confirmation before providing or modifying code that performs them.\n\nIf the user explicitly asks you to proceed without redaction, proceed only after emitting a clear security warning and listing the risks; then follow the user’s instruction but continue to avoid exposing secrets or recommending insecure actions.\nShort checklist for the assistant (perform before acting):\n\nConfirm user redaction: request explicit confirmation (“Reply ‘yes’ to continue”) or an uploaded redacted version.\nScan provided context for obvious secrets/placeholders (API keys, tokens, passwords, connection strings) and flag them with examples.\nRefuse to reveal secrets or to run/execute external code or links.\nRequire explicit confirmation before producing or modifying code that performs unsafe operations (file deletions, system calls, eval/exec, unescaped SQL).\nRecord the user’s confirmation and any residual risks or caveats before proceeding.\n\n\n\n\n\n\n\nReusable prompts\nSame as the prompt above, you can create useful reusable prompts that can help you save time and can also be shared with team members. For example, you can make the prompts from the Protocol section as a reusable prompts. VSCode gives a good explanation of how these can created in its Copilot Tips and Tricks.",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suggested Guidelines for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_guidelines.html#interaction-with-github-copilot",
    "href": "copilot_guidelines.html#interaction-with-github-copilot",
    "title": "Suggested Guidelines for Using GitHub Copilot in Technical Work",
    "section": "Interaction with GitHub Copilot",
    "text": "Interaction with GitHub Copilot\n\nFirst Ask, then Agent: map and agree the solution before making changes\nBefore asking Copilot to modify code (Agent mode), first use the Ask option to explore and agree a solution for the general task. Have Copilot propose a design and refine it until you and the agent share the same approach — this helps avoid unnecessary edits and keeps reviews small.\n\n\n\n\n\n\nNoteExamples of Ask prompts\n\n\n\n\n“What functions would be needed to implement this feature?”\n“How would these functions interact? Describe the workflow or provide a brief diagram.”\n“For each new function, give a short summary: objective, inputs, outputs, and dependencies.”\n“What modifications to existing functions are required? List changes and rationale.”\n\n\n\nOnce the design is mapped and agreed, switch to Agent mode and request the specific code changes. You can iterate on alternatives and trade-offs in Ask mode before implementing. This workflow reduces code churn and the amount of code you must inspect.\n\n\nProvide Feedback to Improve Future Suggestions\nGitHub Copilot learns from your feedback to improve the quality and relevance of future suggestions. Providing feedback helps the AI agent understand what works well and what doesn’t.\nHow to give feedback:\n\nUse thumbs up/down buttons on suggestions or responses when available in the Copilot interface.\nExplicitly tell Copilot when a response is helpful or unhelpful (e.g., “This solution works well” or “This approach doesn’t fit our requirements”).\nIf a suggestion is incorrect or incomplete, explain why and ask for a revised version with specific corrections.\nAccept or reject inline code suggestions to signal which patterns align with your codebase.\n\nWhy feedback is important:\n\nHelps Copilot adapt to your coding style, preferred libraries, and project conventions over time.\nImproves the accuracy of future suggestions for similar tasks.\nSignals to the model which responses are most useful, contributing to better performance.\nSaves time by reducing iterations needed to get the right answer.\n\nProviding clear, specific feedback (rather than just rejecting suggestions) yields the best results for improving Copilot’s future responses.\n\n\nDocument prompts used for key tasks\nWhen using Github Copilot to work on tasks that will need revision by team members, a good idea will be to record the key characteristics of prompts you used. At minimum, ask Github Copilot to capture:\n\nThe context provided (if any): files, code snippets, or system state included with the prompt (what the agent “saw”).\nThe Agent instruction: the explicit task or role you asked the agent to perform (for example, “write a unit test”, “refactor this function for readability”, or “explain this algorithm”).\n\nOther useful prompt characteristics to document:\n\nInput data examples (small sample inputs and expected outputs).\nAny constraints or hard requirements (performance limits, libraries to use, coding style).\nTime or version metadata (date, version of Copilot/IDE/plugins if known).\n\nWhy this helps: keeping a short record of the prompts and their context makes it easier to reproduce results, re-run or refine prompts, and debug situations where generated code fails or causes errors. These notes become especially valuable during future development when tracking regressions or when onboarding colleagues who must understand the original intent.\nPrompt suggested:\n/gpid-guide-document-task\n\nLatest GPID prompt file\n\n\n\n\n\n\nNotegpid-guide-document-task\n\n\n\n\n\nYou are a reporter/recorder assisting with development logging. Required inputs:\n\nTASK_NAME (short string)\nTASK_DESCRIPTION or ORIGINAL_PROMPT (text used to request the work)\nCONTEXT (files, snippets, sample input — include file paths)\nPREVIOUS_LOG (optional — full text of an earlier log to continue)\nREDACTION_CONFIRMED (optional flag: \"yes\" if user has already redacted sensitive data)\n\nSecurity & redaction (required first step)\n\nIf REDACTION_CONFIRMED is missing or not \"yes\", ask: “Please confirm that you have removed credentials, API keys, tokens, passwords, PII, and other private information. Reply ‘yes’ to continue or upload a redacted version.”\nIf the provided context looks like it contains secrets or connection strings, stop and request a redacted version. Do not proceed until user confirms.\nNever output or recreate secrets.\n\nLogging behaviour (start immediately after redaction is confirmed)\n\nIf PREVIOUS_LOG is provided: integrate it as the authoritative history and append new entries. Do not overwrite past entries; annotate any corrections with a short note and timestamp.\nIf PREVIOUS_LOG is not provided: create a new append-only log.\n\nLog entry format (use for every incremental update)\n\nHeader: LOG | TASK_NAME | entry: N | date: YYYY-MM-DDTHH:MM:SSZ\nContext: list file paths used and short excerpt (1-3 lines)\nAgent Instruction: a short summary of the prompt/instruction (1-2 sentences). Include the full prompt in a fenced block only for the first log entry or when the user sets INCLUDE_FULL_PROMPT: yes or explicitly requests it.\nActions Taken: bullet list of steps performed since last entry\nOutcome summary: 1 paragraph summarizing results and current status\nArtifacts / Files changed: suggested paths and brief diff summary\nNext steps: short list of recommended next actions (requires user agreement before saving)\nWhere to store (suggested): copilot_logs/TASK_NAME.md (or alternative path)\n\nOperational rules\n\nAlways include the current log entry number (N), incrementing from the last entry in PREVIOUS_LOG (start at 1 for new logs).\nKeep each entry concise and timestamped (use ISO 8601).\nWhen modifying code or files, list only the file paths changed (no code snippets or diffs).\nAsk clarifying questions when the task or context is ambiguous before proceeding.\n\nResume & continue commands (how the user controls the assistant)\n\nTo append progress: user provides new CONTEXT or instructions; assistant creates the next LOG entry and returns it.\nTo request a draft file for review: user sends GENERATE DRAFT FILE — assistant returns the assembled file content and suggested path (not saved).\nTo finalize the task and return the log-ready file: user sends FINALIZE or RETURN FINAL FILE — assistant:\n\nProposes next steps and asks: “Do you agree with these next steps? Reply ‘yes’ to continue or provide your preferred steps.”\nAfter user confirms, asks: “Do you want to add any other items to the todo list for this log entry? Reply ‘yes’ with your items or ‘no’ to skip.”\nBefore saving, asks: “Do you want to save the following todo items/next steps in the log? [list items]”. Wait for user confirmation (“yes” or edited list).\nAfter confirmation, compiles the full log and any final artifact into a single markdown/text file.\nIncludes a header with TASK_NAME, TASK_DESCRIPTION, start and end dates, and a changelog.\nReturns content ready for file inclusion and a suggested storage path (e.g., copilot_logs/TASK_NAME.md).\n\n\nExample minimal log entry (for illustration):\nLOG | Data-Cleanup | entry: 2 | date: 2026-01-05T14:28:00Z\n\nContext:\n- `R/clean_data.R` (excerpt: `clean_data &lt;- function(df) { df |&gt; ... }`)\n\nAgent Instruction (summary):\nRefactor `clean_data` to handle NA and factor levels; include unit tests. (Full prompt included in entry 1 or on request.)\n\nActions Taken:\n- Added NA-handling to `clean_data`\n- Wrote 4 `testthat` unit tests in `tests/test-clean_data.R`\n\nOutcome summary:\n- `clean_data` now handles NA and unexpected types; tests pass locally (4/4). Minor edge-case for empty inputs remains.\n\nArtifacts / Files changed:\n- `R/clean_data.R`\n- `tests/test-clean_data.R`\n\nNext steps:\n- Review edge-case for empty inputs\n- Run full package checks\n\nWhere to store:\n- `copilot_logs/Data-Cleanup.md`\nReturn format\n\nFor every assistant response that appends the log, return only the new log entry text (ready to paste into the log file) and a one-line suggested storage path.\nOn FINALIZE, return the full assembled file content (complete log + artifacts summary) ready for inclusion in copilot_logs/.\n\nEnd of prompt.",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suggested Guidelines for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "copilot_guidelines.html#other-resources",
    "href": "copilot_guidelines.html#other-resources",
    "title": "Suggested Guidelines for Using GitHub Copilot in Technical Work",
    "section": "Other resources",
    "text": "Other resources\n\nGitHub Copilot in your IDE\nGithub Copilot best practices\nGithub Copilot tips and tricks in Vscode\nMastering Github Copilot Chat",
    "crumbs": [
      "Copilot and AI Tools",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suggested Guidelines for Using GitHub Copilot in Technical Work</span>"
    ]
  },
  {
    "objectID": "code_coverage.html",
    "href": "code_coverage.html",
    "title": "6  Add code coverage badge to your GitHub Repository.",
    "section": "",
    "text": "6.1 Codecov.io\nIn this article we will learn how to add code coverage badge to your GitHub repository.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Add code coverage badge to your GitHub Repository.</span>"
    ]
  },
  {
    "objectID": "code_coverage.html#codecov.io",
    "href": "code_coverage.html#codecov.io",
    "title": "6  Add code coverage badge to your GitHub Repository.",
    "section": "",
    "text": "Create an account at https://about.codecov.io/ , sign up with your GitHub account if you don’t have an account already. Codecov is a popular tool for measuring and visualizing code coverage in software projects. It integrates with GitHub, GitLab, Bitbucket, and other CI/CD systems to provide insights into how much of your code is tested by your test suite.\nYou can sync your private Github repositories on codecov platform to get started. If you want to add code coverage badge to a repository which is part of an organization (like PIP-Technical-Team, GPID-WB etc) then you need to be an admin of that organization. Admin role is needed because to sync the communication between Codecov.io with GitHub we need to generate a token which can only be done by admins.\nOnce your repo is synced with codecov and you can see it there click on Configure to start the process. As an example it should give you this screen\n\n\n\nIf you scroll below it will ask you to generate a repository secret, click on that to get a unique token for your repository and copy it.\nYou can ignore rest of the steps mentioned on that page since those are very generic language agnostic steps and since we want to setup this for R packages, we have a better option which I will share below.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Add code coverage badge to your GitHub Repository.</span>"
    ]
  },
  {
    "objectID": "code_coverage.html#github",
    "href": "code_coverage.html#github",
    "title": "6  Add code coverage badge to your GitHub Repository.",
    "section": "6.2 GitHub",
    "text": "6.2 GitHub\n\nNow, moving to GitHub go to your repository. Click on Settings -&gt; Secrets and Variables -&gt; Actions -&gt; Repository Secrets add the new token with name CODECOV_TOKEN and copy the token value which was generated in the previous step.\n\nNext, we are going to setup GitHub Action to run and calculate code coverage after every push. The calculated coverage report would be uploaded on codecov.io and would be visible on their dashboard.\nAdditionally, I also added a possibility to run R CMD CHECK after every push. R CMD check is a tool that runs a series of automated checks on an R package to ensure it’s correctly structured, documented, and error-free. It helps catch issues in code, tests, and documentation before sharing or submitting to CRAN. So it is like an additional validation that we have on our code.\nThe new workflow file looks like below\nname: R-CMD-check and Codecov\n\non:\n  push:\n    branches: [master]\n  pull_request:\n    branches: [master]\n\njobs:\n  R-CMD-check:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Set up R\n        uses: r-lib/actions/setup-r@v2\n\n      - name: Set up pandoc\n        uses: r-lib/actions/setup-pandoc@v2\n\n      - name: Install dependencies\n        run: |\n          install.packages(c(\"remotes\", \"rcmdcheck\", \"covr\"))\n          remotes::install_deps(dependencies = TRUE)\n        shell: Rscript {0}\n\n      - name: Run R CMD check\n        run: |\n          rcmdcheck::rcmdcheck(args = \"--no-manual\", error_on = \"warning\")\n        shell: Rscript {0}\n\n      - name: Run test coverage\n        run: |\n          covr::codecov()\n        shell: Rscript {0}\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }} \nThis file is self explanatory but briefly, it checks out the repository that we want to run our action on, sets up R to run R CMD CHECK and finally generate code coverage report and upload it to codecov.io .\nOne tip that I can share is to check if this workflow file works on your local branch before running on master branch. To do that you should temporarily enable the workflow file to run on your local branch. This can be done as below -\non:\n  push:\n    branches: [master, your-branch]\nwhere your-branch is the name of the local branch that you want to run the workflow for. Once you have verified that everything works as expected in the local branch, you can remove your-branch from the list again.\nOnce the workflow runs successfully the dashboard on codecov.io should be updated and you should see something like this\n\nEvery time a push or PR is made to master the dashboard will be updated with latest data.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Add code coverage badge to your GitHub Repository.</span>"
    ]
  },
  {
    "objectID": "github_actions.html",
    "href": "github_actions.html",
    "title": "7  Setting up Github Actions for Auto Deployment of Quarto book",
    "section": "",
    "text": "7.1 Introduction\nOne of the best parts of using Quarto for websites, blogs, or reports is how easily it integrates with GitHub Pages. With a simple GitHub Actions workflow, you can automatically render and publish your site every time you update your repository. In this post we are going to learn how we have enabled auto deployment for this quarto book.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Setting up Github Actions for Auto Deployment of Quarto book</span>"
    ]
  },
  {
    "objectID": "github_actions.html#workflow",
    "href": "github_actions.html#workflow",
    "title": "7  Setting up Github Actions for Auto Deployment of Quarto book",
    "section": "7.2 Workflow",
    "text": "7.2 Workflow\nThis is the workflow that we are using in Github Actions . Let’s look at it one by one.\non:\n  workflow_dispatch:\n  push:\n    branches: main\n\nname: Quarto Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        env:\n          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tinytex: true\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n7.2.1 Triggering the Workflow\non:\n  workflow_dispatch:\n  push:\n    branches: main\nThis tells GitHub Actions when to run the workflow. There are two triggers here:\n\npush to main – Any time you commit or merge changes into the main branch, the workflow runs\nworkflow_dispatch – Allows you to manually trigger the workflow from the GitHub Actions tab in your repository. This is useful when you want to force a rebuild and republish without committing new changes.\n\n\n\n7.2.2 Naming the workflow\nname: Quarto Publish\nThis gives the workflow a friendly name that will appear in the Actions tab.\n\n\n7.2.3 Defining the job\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\nHere we’re defining a single job called build-deploy.\n\nruns-on: ubuntu-latest – The job will run inside an Ubuntu-based virtual machine provided by GitHub.\npermissions: contents: write – The workflow needs permission to write to the repository (required for publishing to the gh-pages branch).\n\n\n\n7.2.4 The Steps\n\n7.2.4.1 1. Check out the repository\n- name: Check out repository\n  uses: actions/checkout@v4\nThis makes your repository’s files available in the workflow environment so Quarto can render your project.\n\n\n7.2.4.2 2. Set up Quarto\n- name: Set up Quarto\n  uses: quarto-dev/quarto-actions/setup@v2\n  env:\n    GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n  with:\n    tinytex: true\nThis installs Quarto in the workflow environment. The tinytex: true option ensures LaTeX support is available for rendering PDFs. The GH_TOKEN is github token repository secret that is added in Repo settings -&gt; Secrets and Variables -&gt; Actions . It is used for authentication when publishing.\n\n\n7.2.4.3 3. Render and Publish\n- name: Render and Publish\n  uses: quarto-dev/quarto-actions/publish@v2\n  with:\n    target: gh-pages\n  env:\n    GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\nThis step does two things:\n\nRenders your Quarto project (turns .qmd files into HTML, PDF, or other output formats).\nPublishes the output to the gh-pages branch, which GitHub Pages uses to serve your site. The target: gh-pages option ensures everything is pushed to the right branch.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Setting up Github Actions for Auto Deployment of Quarto book</span>"
    ]
  },
  {
    "objectID": "github_actions.html#dont-ignore-the-.gitignore-file",
    "href": "github_actions.html#dont-ignore-the-.gitignore-file",
    "title": "7  Setting up Github Actions for Auto Deployment of Quarto book",
    "section": "7.3 Don’t ignore the .gitignore file",
    "text": "7.3 Don’t ignore the .gitignore file\nMake sure that your .gitignore file excludes _book, _site folders. These are the folders where Quarto renders HTML/PDF files when testing them locally. These files should not be tracked since Github Actions will build them with our auto deployment process.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Setting up Github Actions for Auto Deployment of Quarto book</span>"
    ]
  },
  {
    "objectID": "github_actions.html#conclusion",
    "href": "github_actions.html#conclusion",
    "title": "7  Setting up Github Actions for Auto Deployment of Quarto book",
    "section": "7.4 Conclusion :",
    "text": "7.4 Conclusion :\nWith this workflow in place, the Quarto book will automatically rebuild and deploy whenever a push is made to the main branch or whenever we manually trigger the workflow. No more running commands locally or remembering to push generated files.\nThis is a clean, reproducible, and automated way to publish your Quarto projects using GitHub Pages. As a side not usethis package has a lot of good utility functions that helps you to set up similar workflow. You may explore using them. A good starting point is usethis::use_github_action(\"render-quarto\").\nFor reference the Quarto book is published here.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Setting up Github Actions for Auto Deployment of Quarto book</span>"
    ]
  },
  {
    "objectID": "Increase_performance_WB_laptop.html",
    "href": "Increase_performance_WB_laptop.html",
    "title": "8  Improve Efficiency of a WB Laptop",
    "section": "",
    "text": "8.1 Modify System Properties for Performance\nThere are a few things you can do to improve the efficiency of a WB laptop. These tips won’t make your laptop fast, but they will help optimize performance and make it feel more responsive.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Improve Efficiency of a WB Laptop</span>"
    ]
  },
  {
    "objectID": "Increase_performance_WB_laptop.html#modify-system-properties-for-performance",
    "href": "Increase_performance_WB_laptop.html#modify-system-properties-for-performance",
    "title": "8  Improve Efficiency of a WB Laptop",
    "section": "",
    "text": "Open the Windows menu, type Run, and click on the Run app.\n\nIn the Run app, type the following command and hit Enter:\n\n   systempropertiesperformance.exe\n\n\nIn the Performance Options window, select the Visual Effects tab.\n\nClick on Adjust for best performance.\nMake sure all the checkboxes are unchecked.\nClick Apply and then OK.\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote: This may affect the appearance of your system, since many visual effects will be disabled.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Improve Efficiency of a WB Laptop</span>"
    ]
  },
  {
    "objectID": "Increase_performance_WB_laptop.html#battery-settings",
    "href": "Increase_performance_WB_laptop.html#battery-settings",
    "title": "8  Improve Efficiency of a WB Laptop",
    "section": "8.2 Battery Settings",
    "text": "8.2 Battery Settings\n\nOpen Battery Settings. \nSet the battery mode to Best performance.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Improve Efficiency of a WB Laptop</span>"
    ]
  },
  {
    "objectID": "Increase_performance_WB_laptop.html#google-chrome-settings",
    "href": "Increase_performance_WB_laptop.html#google-chrome-settings",
    "title": "8  Improve Efficiency of a WB Laptop",
    "section": "8.3 Google Chrome Settings",
    "text": "8.3 Google Chrome Settings\n\nIn Google Chrome, type the following in the address bar:\nchrome://settings/performance\nUnder the Memory section, select Maximum.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Improve Efficiency of a WB Laptop</span>"
    ]
  },
  {
    "objectID": "interact_vm.html",
    "href": "interact_vm.html",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "",
    "text": "9.1 Access and Session Management",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#access-and-session-management",
    "href": "interact_vm.html#access-and-session-management",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "",
    "text": "9.1.1 Login to the VM\n\nGo to PrivX.\nUse SSO login (World Bank Authenticator App).\nIn the Connections tab, select the VM you want:\n\nDevelopment: Linux-wzlxdpip01.worldbank.org\nQA: Linux-wzlxqpip01.worldbank.org\nProduction: Linux-wzlxppip01.worldbank.org\n\nOnce connected, switch to the srvpip user:\nsudo su - srvpip\n\n\n\n9.1.2 Copy, Paste, and Keyboard Shortcuts\n\n\n\n\n\n\n\n\nShortcut\nAction\nNotes\n\n\n\n\nCtrl + C\nStop the current running process\ne.g. stop an infinite loop or hanging R process\n\n\nCtrl + D\nLog out of the current shell\nEnds your session as srvpip\n\n\nShift + Ctrl + V\nPaste from clipboard\nWorks in most PrivX terminals\n\n\nShift + Insert\nPaste (alternative)\nOften easier in remote shells\n\n\n\nNotice that Ctrl + C does not copy text in terminal. You only need to highlight with your mouse the section you want to copy. Once you stopped highlighting, the text is copied to your clipboard automatically.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#understanding-the-environment",
    "href": "interact_vm.html#understanding-the-environment",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.2 Understanding the Environment",
    "text": "9.2 Understanding the Environment\n\n9.2.1 Users and Permissions\n\nYour account: initial login via PrivX (not root)\nsrvpip user: used to manage Docker containers\nroot user: required for system-level commands; use only with sudo\n\nCommon prefixes:\n\ndocker → run Docker as normal user (often fails without permissions)\nsudo docker → correct way when managing containers\nsudo su - srvpip → switch to service account context\n\n\n\n9.2.2 Architecture Overview\n+-------------------------------------------------------------+\n|                      Linux VM (Host)                        |\n|                                                             |\n|  Persistent Data:                                           |\n|    /Data/pip/files/data   &lt;---+                             |\n|                               | (bind mount)                |\n|                               v                             |\n|  ---------------------------------------------------------  |\n|  |               Docker Container: povertyscoreapi       |  |\n|  |                                                     |  |\n|  |   - Mounts /Data/pip/files/data → /Data             |  |\n|  |   - Runs: Rscript /app/main.R                       |  |\n|  |   - Listens on port 8080 (internal)                 |  |\n|  ---------------------------------------------------------  |\n|                               ^                             |\n|                               |                             |\n|  Host Port 80  &lt;--------------+  (mapped to container 8080) |\n+-------------------------------------------------------------+\nLegend: - Data written to /Data inside the container is actually stored on the host at /Data/pip/files/data. - The API runs inside the container on port 8080, but is accessible from outside the VM on port 80.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#essential-docker-commands-cheat-sheet",
    "href": "interact_vm.html#essential-docker-commands-cheat-sheet",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.3 Essential Docker Commands (Cheat Sheet)",
    "text": "9.3 Essential Docker Commands (Cheat Sheet)\n\n\n\n\n\n\n\n\n\nTask\nCommand\nNotes\n\n\n\n\n\nList all containers\nsudo docker ps -a\nShows running & stopped\n\n\n\nView logs\nsudo docker logs -f povertyscoreapi\nAdd --tail 200 to see last lines\n\n\n\nEnter container shell\nsudo docker exec -it povertyscoreapi /bin/bash\nFor interactive debugging\n\n\n\nCheck mounted volumes\nsudo docker inspect povertyscoreapi             | grep Mounts -A 5\nSee /Data source\n\n\n\nDelete stopped containers\nsudo docker container prune\nCleans unused ones\n\n\n\nDelete old images\nsudo docker image prune -a\nBe cautious — removes all unused\n\n\n\nCheck Docker service status\nsudo systemctl status docker\nConfirms Docker is active",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#managing-data",
    "href": "interact_vm.html#managing-data",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.4 Managing Data",
    "text": "9.4 Managing Data\n\n9.4.1 Data on the VM (Persistent)\n\nMain data location:\ncd /Data/pip/files/data\nInspect space usage:\ndf -h | grep Data\ndu -h --max-depth=1 | sort -h\nPreview files safely:\nls -lah\nView folder sizes:\ndu -sh *\n\n\n9.4.1.1 🔍 Find large or old files\nfind /Data/pip/files/data -type f -mtime +365 | head -n 20\n\n\n\n\n9.4.2 Data Inside Containers (Ephemeral)\nCheck where containers mount volumes:\nsudo docker inspect povertyscoreapi | grep Mounts -A 5\nYou’ll see:\n\"Mounts\": [\n  {\n    \"Type\": \"bind\",\n    \"Source\": \"/Data/pip/files/data\",\n    \"Destination\": \"/Data\"\n  }\n]\nThat means:\n\nInside container → /Data\nOn host → /Data/pip/files/data\n\n\n9.4.2.1 Access via container shell:\nsudo docker exec -it povertyscoreapi ls -lh /Data\n\n\n\n\n9.4.3 Safe Deletion and Cleanup\nPreview first:\nls -d /Data/pip/files/data/project_*\nDelete specific folders:\nrm -rf /Data/pip/files/data/folder1 /Data/pip/files/data/folder2\nDelete all contents but keep parent folder:\nrm -rf /Data/pip/files/data/*\nMove to trash instead of deleting:\nmkdir -p /Data/pip/files/trash\nmv /Data/pip/files/data/folder1 /Data/pip/files/trash/\n⚠️ Caution: rm -rf is irreversible — always check with ls first.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#diagnosing-api-or-container-issues",
    "href": "interact_vm.html#diagnosing-api-or-container-issues",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.5 Diagnosing API or Container Issues",
    "text": "9.5 Diagnosing API or Container Issues\n\n9.5.1 Check Container State\nsudo docker ps -a\nGet detailed exit info:\nsudo docker inspect povertyscoreapi --format='ExitCode={{.State.ExitCode}} OOMKilled={{.State.OOMKilled}}'\n\nExitCode=0 → normal exit\nExitCode=137 → killed (likely out of memory)\n\n\n\n\n9.5.2 View Logs\nsudo docker logs povertyscoreapi | head -n 20   # startup logs\nsudo docker logs --tail 200 povertyscoreapi     # recent logs\n\n\n\n9.5.3 Reproduce Interactively\nStart an interactive debug session:\nsudo docker run --rm -it \\\n  --name povertyscoreapi-debug \\\n  -p 8080 \\\n  -v /Data/pip/files/data:/Data \\\n  itsesippscoreregistryprod.azurecr.io/povertyscoreapi:latest \\\n  /bin/bash\nInside:\nRscript /app/main.R\nPress Ctrl + C to stop and exit to leave.\n\n\n\n9.5.4 Restart or Rebuild Containers\nsudo docker restart povertyscoreapi\nOr rebuild completely:\nsudo docker stop povertyscoreapi\nsudo docker rm povertyscoreapi\nsudo docker pull itsesippscoreregistryprod.azurecr.io/povertyscoreapi:latest\nsudo docker run -d --name povertyscoreapi \\\n  -p 80:8080 \\\n  -v /Data/pip/files/data:/Data \\\n  itsesippscoreregistryprod.azurecr.io/povertyscoreapi:latest",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#testing-api-endpoints",
    "href": "interact_vm.html#testing-api-endpoints",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.6 Testing API Endpoints",
    "text": "9.6 Testing API Endpoints\n\n9.6.1 From Inside the Container\ncurl http://localhost:80/api/v1/health-check\n\n\n9.6.2 Loop through common endpoints\nfor ep in health-check pkgs-version data-signature gh-hash; do\n  echo \"---- Testing $ep ----\"\n  curl -s http://localhost:80/api/v1/$ep\n  echo\ndone\n\n\n9.6.3 From Outside (VM host or browser)\ncurl http://wzlxdpip01.worldbank.org/api/v1/health-check",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#troubleshooting-common-errors",
    "href": "interact_vm.html#troubleshooting-common-errors",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.7 Troubleshooting Common Errors",
    "text": "9.7 Troubleshooting Common Errors\n\n\n\n\n\n\n\n\nSymptom\nLikely Cause\nFix\n\n\n\n\ncurl: (7) Failed connect\nContainer not running or wrong port\nsudo docker ps -a\n\n\nExited (137)\nOut of memory (OOMKilled)\nIncrease VM memory or limit API load\n\n\nauthentication required\nNot logged in to Azure Container Registry\nsudo az acr login --name itsesippscoreregistryprod\n\n\npermission denied on /Data\nWrong user ownership\nsudo chown -R srvpip /Data\n\n\nNo logs shown\nContainer failed before startup\nRun sudo docker inspect povertyscoreapi\n\n\nPort 8080 works but 80 doesn’t\nPort not mapped\nRun container with -p 80:8080",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#understanding-ports-80-vs-8080",
    "href": "interact_vm.html#understanding-ports-80-vs-8080",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.8 Understanding Ports (80 vs 8080)",
    "text": "9.8 Understanding Ports (80 vs 8080)\n\nInside Docker, the API runs on 8080:\npipapi::start_api(port = 8080, host = \"0.0.0.0\")\nOutside Docker (host or browser), you can map any port using:\n-p 80:8080\nThis means:\nhost_port:container_port\nSo users access:\nhttp://wzlxdpip01.worldbank.org/api/v1/...\neven though internally it listens on 8080.",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#monitoring-resource-usage",
    "href": "interact_vm.html#monitoring-resource-usage",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.9 Monitoring Resource Usage",
    "text": "9.9 Monitoring Resource Usage\nWatch real-time CPU and memory:\nsudo docker stats povertyscoreapi\nOr globally:\ntop -u srvpip",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  },
  {
    "objectID": "interact_vm.html#appendix",
    "href": "interact_vm.html#appendix",
    "title": "9  How to interact with the Virtual Machine (VM) that hosts PIP",
    "section": "9.10 Appendix",
    "text": "9.10 Appendix\n\n9.10.1 Check Disk Usage Quickly\ndf -h | grep Data\n\n\n9.10.2 Check Docker Service Logs\nsudo journalctl -u docker --since \"2025-09-23 17:00\"\n\n\n9.10.3 Check R version inside container\nsudo docker exec -it povertyscoreapi Rscript -e \"R.version.string\"",
    "crumbs": [
      "MISC Tools and Tips",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>How to interact with the Virtual Machine (VM) that hosts PIP</span>"
    ]
  }
]